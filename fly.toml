# fly.toml app configuration file generated for system-llm-chat on 2025-10-29T21:36:42+07:00
#
# See https://fly.io/docs/reference/configuration/ for information about how to use this file.
#

app = 'system-llm-chat'
primary_region = 'sin'

[build]

[env]
  HOSTNAME = "0.0.0.0"
  PORT = "3000"
  NEXT_PUBLIC_API_BASE_URL = "https://system-llm-backend-121635597125.asia-southeast2.run.app/api/v1"
  NEXT_PUBLIC_APP_NAME = "System LLM"

[http_service]
  internal_port = 3000
  force_https = true
  auto_stop_machines = 'stop'
  auto_start_machines = true
  min_machines_running = 0
  processes = ['app']

[[vm]]
  memory = '1gb'
  cpu_kind = 'shared'
  cpus = 1
